:math:
:imagesdir: ./images
:imagesoutdir: generated_images
:stem: latexmath

= Tutorial 07: Markieren/Auswählen von Flächen (mit OpenMP Parallelisierung)

In diesem Tutorial geht es darum, Flächen bzw. Objekte in der Scene auszuwählen.

.Tutorial_07, Visualisierung eines Bildschirmstrahls
image::Tutorial_07_RayTracking.png[Tutorial_07,pdfwidth=8cm]

[NOTE]
====
Quelltext für dieses Tutorial liegt im github repo:  https://github.com/ghorwin/OpenGLWithQt-Tutorial/tree/master/code/Tutorial_07[Tutorial_07]
====

Es gibt hier 2 Techniken, die verfolgt werden sollen:

- Rendern in einen offscreen-Framenbuffer mit individuellen Farben aller anklickbaren Objekte und Identifizierung der Objekte durch Abbildung der Farben auf originale Objekte/Flächen
- Strahlenverfolgung (Ray Picking), d.h. Bestimmung der Sichtlinie im Weltenkoordinatensystem und dann Schnittpunktberechnung aller Objekte und Sortierung nach Tiefe (aufgrund der vielen Objekte und eindeutig parallelem Algorithmus ist dies ein klassisches Anwendungsgebiet für OpenMP).

Auch dieses ist ein grundlegendes 3D Grafik-Prozedere und in diesem Tutorial nur drin, um die Verwendung der Klasse `QOpenGLFrameBuffer` zu demonstrieren. Allerdings zeigt es auch die annehmlichkeiten der `QMatrix4x4`, `QVector4D` und `QVector3D` Klassen.

== Option 1: Strahlenverfolgung

Der Grundgedanke ist einfach: Die Mausposition im lokalen Fenster umrechnen in Weltkoordinaten und entlang dieser Linie alle Schnittpunkte mit auswählbaren Objekten finden. Das näheste Objekte zum Betrachter ist dann das ausgewählte Objekt. 

Die Welt (in der perspektivischen Darstellung) hat eine _near plane_ und eine _far plane_. Alles davor und dahinter wird geklippt und nicht dargestellt. Daher kann hier auch nichts sinnvoll ausgewählt werden. Der Betrachter schaut durch die _near plane_ hindurch auf die Scene, und der Blickstrahl trifft irgendwo hinten auf die _far plane_. Da der Blickstrahl senkrecht zum Bildschirmoberfläche steht, sieht man die Linie selbst nur als Punkt.

Die Berechnung ist hinreichend trivial:

. Globale Mauskoordinaten von `QCursor::pos()` in lokale Mauskoordinaten umrechnen (mittels https://doc.qt.io/qt-5/qwidget.html#mapFromGlobal[QWindow::mapFromGlobal()] )

. Mausposition des lokalen Fensters in Normalized Device Coordinates (NDC) umrechnen. Dabei hilft sich vorzustellen, dass das Fenster das normalisierte x-y-Koordinatensystem beinhaltet, mit dem Mittelpunkt genau in der Mitte des Fensters und der Ausdehnung -1..1 in beide Achsen. Wenn man also genau in die Mitte klickt, ist das 0,0 in NDC. Ganz oben links geklickt ist das -1,1 (y-Achse zeigt nach oben in NFC). Die z-Koordinate ist -1 für die _far plane_ und 1 für die _near plane_. W-Komponente auf 1 setzen.

. Model2Projection-Matrix (also Produkt aller Transformationsmatrizen) invertieren
. Beide Punkte mit der inversen Matrix transformieren

Fertig. Hier ist der Quelltext:

.SceneView.cpp:pick()
[source,c++]
----
void SceneView::pick(const QPoint & globalMousePos) {
	// local mouse coordinates
	QPoint localMousePos = mapFromGlobal(globalMousePos);
	int my = localMousePos.y();
	int mx = localMousePos.x();

	// viewport dimensions
	const qreal retinaScale = devicePixelRatio(); // needed for Macs with retina display
	qreal vpw = width()*retinaScale;
	qreal vph = height()*retinaScale;

	// invert world2view matrix, with m_worldToView = m_projection * m_camera.toMatrix() * m_transform.toMatrix();
	bool invertible;
	QMatrix4x4 projectionMatrixInverted = m_worldToView.inverted(&invertible);
	if (!invertible) {
		qWarning()<< "Cannot invert projection matrix.";
		return;
	}

	// mouse position in NDC space, one point on near plane and one point on far plane
	float halfVpw = vpw/2.0;
	float halfVph = vph/2.0;
	QVector4D near(
				(mx - halfVpw) / halfVpw,
				-1*(my - halfVph) / halfVph,
				-1,
				1.0);

	QVector4D far(
				near.x(),
				near.y(),
				1,
				1.0);

	// transform from NDC to model coordinates
	QVector4D nearResult = projectionMatrixInverted*near;
	QVector4D farResult = projectionMatrixInverted*far;
	// don't forget normalization!
	nearResult /= nearResult.w();
	farResult /= farResult.w();

	// update pick line vertices (visualize pick line)
	m_context->makeCurrent(this);
	m_pickLineObject.setPoints(nearResult.toVector3D(), farResult.toVector3D());
}
----

Ganz am Ende wird noch ein neu eingeführtes OpenGL-Zeichenobjekt aktualisiert. Nach der Lektüre von _Tutorial 05_ sollte der Quelltext in `PickLineObject.*` selbsterklärend sein. Diese Objekt nutzt übrigends den gleichen Vertex- und Fragmentshader wie er für die Boxen eingesetzt wird.

=== Erkennung von Mausklick-Ereignissen

Bisher wurde mit dem Eingabemanager das Gedrückthalten der rechten Maustaste behandelt. Nun soll aber darauf reagiert werden, dass die linke Maustaste geklickt wurde (Linksklick=Auswahl). Das macht man am besten, indem man auf das Loslassen der Maustaste wartet. Gleichzeitig muss man sich dann aber die Position der Maus beim Loslassen merken, da die Maus ja hinterher noch bewegt werden kann.

Der Eingabemanager hat ja, wie in _Tutorial 05_ erklärt, für Tasten (einschließlich Maustasten) einen Zustand "Wurde gedrückt". Den kann man nun einfach abfragen, z.B. in `SceneView::checkInput()`:

.SceneView::checkInput()
[source,c++]
----
void SceneView::checkInput() {
	// this function is called whenever _any_ key/mouse event was issued

    ....

	// has the left mouse butten been release
	if (m_keyboardMouseHandler.buttonReleased(Qt::LeftButton)) {
		m_inputEventReceived = true;
		renderLater();
		return;
	}

    ....
}
----

Die Funktion `KeyboardMouseHandler::buttonReleased(btn)` macht dabei nichts weiter, als zu prüfen, ob der Status der Taste auf `KeyboardMouseHandler::StateWasPressed` steht.

In der selben Art und Weise, wie auf andere Tastendrücke und Mausbewegungen reagiert wurde, kann man nun die Auswahlroutine anstoßen:

.SceneView::processInput()
[source,c++]
----
void SceneView::processInput() {
    ....
    
	// check for picking operation
	if (m_keyboardMouseHandler.buttonReleased(Qt::LeftButton)) {
		pick(m_keyboardMouseHandler.mouseReleasePos());
	}

	// finally, reset "WasPressed" key states
	m_keyboardMouseHandler.clearWasPressedKeyStates();

    ....
}
----

Wichtig ist hier vielleicht nur, dass man abschließend auch die Flags der Maustasten zurücksetzt.

Mit dem derzeitigen Quelltextstand kann man nun wild in der Scene herumklicken, wobei man natürlich erstmal nichts sieht. Erst bei Bewegung in der Scene wird die nun visualisierte Sichtgerade erkennbar - bis zum nächsten Linksklick.

=== Finden von angeklickten Objekten

Die zweite, auch nicht sonderlich komplizierte Aufgabe besteht darin, alle Objekte zu finden, die von der Sichtlinie geschnitten werden. Wenn es sich hierbei um Flächen handelt, ist das recht einfache Mathematik aus dem Tafelwerk (siehe https://de.wikipedia.org/wiki/Analytische_Geometrie[Wikipedia]).

====

*Mathematische Grundlagen*

Ich schreibe die Mathematik hier nochmal kurz auf (aber nur um zu testen, wie man mit Asciidoctor ordentliche Gleichungen hinbekommt :-) )

Ebenengleichung in Normalenform, mit *a* als Bezugspunkt der Ebene und *n* als Normalenvektor:

[latexmath] 
++++
(\boldsymbol{x}-\boldsymbol{a}) \cdot \boldsymbol{n} = 0
++++

Geradengleichung, mit *d* als Richtung und *s* als Startpunkt:

[latexmath] 
++++
\boldsymbol{x} = \boldsymbol{s} + t \, \boldsymbol{d} 
++++

Einsetzen und Ausmultiplizieren ergibt:

[latexmath] 
++++
t_0 = \frac{\left( \boldsymbol{a} - \boldsymbol{s}\right) \cdot \boldsymbol{n}}{\boldsymbol{d} \cdot \boldsymbol{n}}
++++

Falls der Richtungsvektor der Geraden *d* und der Normalenvektor *n* senkrecht aufeinanderstehen wird der Nenner zu 0, d.h. die Gerade liegt parallel zur Ebene (entweder neben oder in der Ebene, ist uns aber hier egal).


Ob eine begrenzte _Fläche_ von der _Strecke_ (unserer Sichtlinie) geschnitten wird, hängt von der Lage des Schnittpunkts ab.

Wird die Sichtlinie durch den Start- und Endpunkt *p1* und *p2* (near und far-Punkte) definiert, und damit *s* = *p1* und *d* = *p2* - *p1*, dann muss t zwischen 0 und 1 liegen (Bedingung 1).

Der berechnete Schnittpunkt

[latexmath] 
++++
\boldsymbol{x_0} = \boldsymbol{s} + t_0 \, \boldsymbol{d} 
++++

liegt in der Ebene. Man kann nun die Ebenengleichung in Parameterform schreiben und die Parameter für den Schnittpunkt bestimmen. Wiederum definieren wir die Ebene über die Eckpunkte, hier *a*, *b* und *c*:

[latexmath] 
++++
\boldsymbol{x} = \boldsymbol{a} + r\, (\boldsymbol{b} - \boldsymbol{a}) + s\, (\boldsymbol{c} - \boldsymbol{a})
++++

Der Normalenvektor für die Schnittpunktberechnung oben ist dann:

[latexmath] 
++++
\boldsymbol{n} = (\boldsymbol{b} - \boldsymbol{a}) \times (\boldsymbol{c} - \boldsymbol{a})
++++

Nach Einsetzen und Auflösen nach _r_ und _s_ kann man prüfen, ob sowohl _r_ als auch _s_ zwischen 0 und 1 liegen (Bedingung 2).
====

Nachdem nun die Mathematik klar ist, hier nochmal die Zusammenfassung des Angeklickt-Prüf-Algorithmus:

- (Vorberechnung: Normalenvektor)
- Prüfung ob Sichtgeradenvektor und Normalenvektor der Ebene zueinander zeigen (Skalarprodukt der Vektoren liefert (absoluten) Winkel < 90°) (damit ist auch der Fall "Gerade liegt parallel zur Ebene" ausgeschlossen)
- Berechnung Schnittpunkt (Geradenfaktor _t_) und Test, ob im Interval [ 0..1]
- Berechnung Punkt in Ebene (Faktoren _r_ und _s_) und Test, ob im Interval [0..1]

[NOTE]
====
Falls statt einer rechteckigen Ebene ein Dreieck getestet wird, so muss bei der Schnittpunktprüfung gelten: 

latexmath:[r \ge 0], latexmath:[s \ge 0] und latexmath:[r + s \le 1]
====

Falls die Ebene 






== Option 2: Falschfarbenrendering

Technisch gibt es eine Einschränkung: es stehen *256^4 - 1* Farben stehen zur Verfügung (rgba) für ebenso viele Elemente. Reicht das nicht aus, muss entweder gefiltert werden (d.h. nur die _prinzipiell_ sichtbaren Objekte bekommen eine Nummer/Farbe), oder man benutzt Ray-Tracking.

Die zahlreichen Tutorials zum Thema _Picking_ verwenden die folgende Technik:

- Schleife über alle anklickbaren Elemente

    * Setzen der eindeutigen Farbe je Element via `uniform` im Shader
    * Zeichen jedes Elements via `glDrawXXX`-Aufruf

- Lesen der Pixelfarbe unter dem Mauscursor

Unnötig zu erwähnen, dass alleine die Vielzahl an `glDrawXXX` Calls problematisch ist. Außerdem ist es je anch Anwendung nicht notwendig, dieses Prozedere bei _jedem_ Mausklick zu wiederholen.

=== Optimierungsidee für quasi-statische Szenen

Nehmen wir mal an, es handelt sich um ein Programm mit vorwiegend nicht-animierten Szenen (Zielvorgabe dieses Tutorials). Dann könnte man die Falschfarbenberechnung stets kurz nach dem Abschluss der Kamerabewegung machen (d.h. mit kleiner Zeitverzögerung), und das resultierende Falschfarbenbild im CPU-Speicher vorhalten. Wenn man nun mit der Maus klickt, hat man sofort den Farbwert unter dem Mauscursor zur Hand. Man könnte auch viele Klicks abfragen, ohne die GPU zu beschäftigen.

Ist sicher eine recht einfache Variante und klingt super nach Arbeitseinsparung. Vor allem, wenn bei der Anwendungen ein Auswahl-Klick in der Scene zunächst nur mit irgendeiner Art der Hervorhebung verbunden ist. Die Scene müsste dann zwar neu gezeichnet werden, aber an der Falschfarbendarstellung zur Auswahl ändert sich nichts.

Ohne die kleine "mit etwas Verzögerung zeichnen" Optimierung sieht der Algorithmus dann also so aus:

- Falls Scenensicht bewegt: zeichnen der Scene in einen Framebuffer, wobei hier der Vertexshader die Farben der Flächen aus einem separaten Farbpuffer holt - dies erlaubt weiterhin die Verwendung von Indexlisten und Vertexarrays
- Zeichnen der Scene wie gehabt

Wir brauchen dafür also:
- ein weiteres ShaderProgramm, welches die Koordinaten aus dem Vertexarray (mit interleaved Storage) liest, aber die Falsch-Farben aus einem _separaten Puffer_ holt
- einen Framebuffer, in den die Falschfarbendarstellung kopiert wird
- eine Möglichkeit, die Farbwerte des Puffers im CPU-Speicher abzulegen
- eine Abfrage der Farbwerte und Identifikation des angeklickten Elements

