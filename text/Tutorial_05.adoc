:imagesdir: ./images
= Tutorial 05: Maus- und Tastatureingaben

In diesem Tutorial geht es primär um Maus- und Tastatureingaben. Und damit das irgendwie Sinn macht, brauchen wir ein (schön großes) 3D Modell, und deshalb ist dieses Tutorial auch _sehr sehr lang_.

.Tutorial_05 (Linux Screenshot), "Die Welt aus 10000 und einer Box"
image::Tutorial_05_linux.png[Tutorial_05,pdfwidth=8cm]

[NOTE]
====
Quelltext für dieses Tutorial liegt im github repo:  https://github.com/ghorwin/OpenGLWithQt-Tutorial/tree/master/code/Tutorial_05[Tutorial_05]
====

In diesem Tutorial werden viele neue Dinge verwendet:

- zwei Modelle (eins für die Boxen und eins für das Gitter), nebst dazugehörigen, unterschiedlichen Shaderprogrammen (das vom Gitter verwendet in die Tiefe abgeblendete Farben)
- Tiefenpuffer, sodass Gitterlinien/Boxen korrekt vor/hintereinander gezeichnet werden
- Model2World und World2View-Matrizen (mit perspektivischer Projektion)
- Shaderprogramme und Renderobjekte (bzw. Objektgruppen) sind in Klassen zusammengefasst, wodurch der Quelltext deutlich übersichtlicher wird
- eine Maus+Tastatursteuerung (WASDQE + Mauslook, incl. Shift-Langssam-Bewege-Modus) ist integriert
- und das Ganze wieder mit dem Schwerpunkt: Rendern nur wenn notwendig (Akku sparen!)

== Überblick

Das Tutorial ist sehr lang, und der Quelltext entsprechend auch. Daher gehen wir in diesem Tutorial schrittweise vor. Die gezeigten Quelltextausschnitte stimmen daher nicht immer 100% mit dem finalen Quelltext überein (ich hab da aus didaktischen Gründen immer mal was weggelassen).

Folgende Implementierungsschritte werden besprochen:

- Anpassung der Klasse `OpenGLWindow` an die in `QOpenGLWidget` bzw. `QOpenGLWindow` verwendeten Funktionsnamen
- Vorstellung der Klasse `SceneView`, die das bisherige `TriangleWindow` oder `RectangleWindow` ersetzt
- Transformationsmatrizen: Model -> World -> Kamera -> Projektion (Klassen `Transform3D` und `Camera`)
- Kapselung der Shaderprogramme und Initialisierung und Verwendung derselben
- Kapselung der Zeichenroutinen für das Gitterraster, Abblendeffekt am Horizont im Shader
- Kapselung der Zeichenroutinen für die Boxen


== Fenster-Basisklasse OpenGLWindow

Als Grundlage für die Implementierung wird die Klasse `OpenGLWindow` aus _Tutorial 01_ verwendet, allerdings etwas abgewandelt. Letztlich wird die Schnittstelle angepasst, um ungefähr der des `QOpenGLWidget` zu entsprechend:
[source,c++]
----
class OpenGLWindow : public QWindow, protected QOpenGLFunctions {
	Q_OBJECT
public:
	explicit OpenGLWindow(QWindow *parent = nullptr);

	void initOpenGL();

public slots:
	void renderLater();
	void renderNow();

protected:
	bool event(QEvent *event) override;
	void exposeEvent(QExposeEvent *event) override;
	void resizeEvent(QResizeEvent *) override;

	virtual void initializeGL() = 0;
	virtual void resizeGL(int width, int height) { Q_UNUSED(width) Q_UNUSED(height) }
	virtual void paintGL() = 0;

	QOpenGLContext *m_context;
};
----

Die Funktionen `initializeGL()` und `paintGL()` sind aus den vorangegangen Tutorials bekannt. Die Funktion `resizeGL()` ist eigentlich nur eine Bequemlichkeitsfunktion, welche aus dem Eventhandler `resizeEvent()` aufgerufen wird.

Neu ist jedoch die Funktion `initOpenGL()`, mit der die OpenGL-Initialisierung gezielt angestoßen werden kann. Normalerweise wird die Initialisierung beim ersten Anzeigen des Fensters (genaugenommen beim ersten ResizeEvent) aufgerufen. Dies kann aber für eine sinnvolle Fehlerbehandlung zu spät sein, weil dann das Fenster wahrscheinlich leer angezeigt wird. Daher ist es sinnvoll, die Funktion nach dem Erstellen des Renderfensters, aber vor Aufruf von `show()` auszuführen.

Macht man das nicht, so wird diese Funktion wie bisher automatisch beim ersten Anzeigen aufgerufen, konkret im ResizeEvent-Handler:

.OpenGLWindow.cpp: Funktion resizeEvent()
[source,c++]
----
void OpenGLWindow::resizeEvent(QResizeEvent * event) {
	QWindow::resizeEvent(event);

	// initialize on first call
	if (m_context == nullptr)
		initOpenGL();

	resizeGL(width(), height());
}
----

Unabhängig von dieser Initializierungsfunktion muss man natürlich die Funktion `initializeGL()` implementieren. Alles andere in der Klasse ist altbekannt.

== Klasse SceneView - die konkrete Implementierung

=== Klassendeklaration

Zwecks Überblick, die Klassendeklaration in Teilen. Zunächst die üblichen Verdächtigen:

.SceneView.h, Deklaration der Klasse SceneView
[source,c++]
----
class SceneView : public OpenGLWindow {
public:
	SceneView();
	virtual ~SceneView() override;

protected:
	void initializeGL() override;
	void resizeGL(int width, int height) override;
	void paintGL() override;
----

Dann kommen die Ereignisbehandlungsroutinen für die Tastatur- und Mauseingaben. Dazu gehören auch die Hilfsfunktionen `checkInput()` und `processInput()`, die im Abschnitt zur Tastatur- und Mauseingabe erklärt sind. Die Member-Variablen `m_keyboardMouseHandler` und `m_inputEventReceived` gehören auch dazu.

.SceneView.h, Deklaration der Klasse SceneView, fortgesetzt
[source,c++]
----
	void keyPressEvent(QKeyEvent *event) override;
	void keyReleaseEvent(QKeyEvent *event) override;
	void mousePressEvent(QMouseEvent *event) override;
	void mouseReleaseEvent(QMouseEvent *event) override;
	void mouseMoveEvent(QMouseEvent *event) override;
	void wheelEvent(QWheelEvent *event) override;

private:
	void checkInput();
	void processInput();

	KeyboardMouseHandler		m_keyboardMouseHandler;
	bool						m_inputEventReceived;
----

Dann kommt die Funktion `updateWorld2ViewMatrix()` zur Koordinatentransformation und die dazugehörigen Member-Variablen.

.SceneView.h, Deklaration der Klasse SceneView, fortgesetzt
[source,c++]
----
	void updateWorld2ViewMatrix();

	QMatrix4x4					m_projection;
	Transform3D					m_transform;
	Camera						m_camera;
	QMatrix4x4					m_worldToView;
----

Zuletzt kommen Member-Variablen, die die Shader-Programme und Zeichenobjekte kapseln (beinhalten Shader, VAO, VBO, EBO, etc.)

.SceneView.h, Deklaration der Klasse SceneView, fortgesetzt
[source,c++]
----
	QList<ShaderProgram>		m_shaderPrograms;

	BoxObject					m_boxObject;
	GridObject					m_gridObject;
};

----

Und das war's auch schon - recht kompakt, oder?

=== Das Aktualisierungskonzept

Erklärtes Ziel dieser OpenGL-Implementierung ist, nur dann zu rendern, wenn es wirklich notwendig ist. Also:

- wenn die Fenstergröße (Viewport) verändert wurde,
- wenn das Fenster angezeigt/sichtbar wird (exposed),
- wenn durch Nutzerinteraktion die Kameraposition verändert wird
- wenn die Szene selbst transformiert wird (z.B. programmgesteuerte Animation...)

Wenn man jetzt bei jedem Eintreffen eines solchen Ereignisses jedesmal neu zeichnen würde, wäre das mit ziemlichem Overhead verbunden. Besser ist es, beim Eintreffen eines solchen Ereignisses einfach nur ein Neuzeichnen anzufordern. Da die `UpdateRequest`-Ereignisse normalerweise mit der Bildschirmfrequenz synchronisiert sind, kann es natürlich sein, dass mehrfach hintereinander `UpdateRequest`-Events an die Eventloop angehängt werden. Dabei werden diese aber zusammengefasst und nur ein Event ausgeschickt. Es muss ja auch nur einmal je angezeigtem Frame gezeichnet werden.

Grundsätzlich muss man also nur die Funktion https://doc.qt.io/qt-5/qwindow.html#requestUpdate[QWindow::requestUpdate()] (oder unsere Bequemlichkeitsfunktion `renderLater()`) aufrufen, damit beim nächsten VSync wieder neu gezeichnet wird.

Leider funktionier das Verfahren im Fall des `ExposeEvent` nicht perfekt. Gerade unter Windows führt das beim Vergrößern des Fensters zu unschönen Artefakten am rechten und unteren Bildschirmrand. Daher muss man in diesem Fall tatsächlich gleich in der Ereignisbehandlungsroutine neu zeichnen und dabei den OpenGL Viewport bereits an die neue Fenstergröße anpassen (das geschieht aber bereits in `OpenGLWindow::exposeEvent()`).

Beim `ResizeEvent` ist zu beachten, dass beim Vergrößern des Fensters allerdings __nur__, wenn der Aufruf nicht zusammen mit einem `ExposeEvent` stattfindet. Daher sollte man in der Funktion `SceneView::resizeEvent()` _nicht_ `renderLater()` aufrufen!

Ohne eine Aufruf von `renderLater()` im ResizeEvent-Handler, erhält man folgende Aufrufreihenfolge bei der Fenstervergrößerung:

----
OpenGLWindow::resizeEvent()
OpenGLWindow::exposeEvent()
SceneView::paintGL(): Rendering to: 1222 x 891
OpenGLWindow::resizeEvent()
OpenGLWindow::exposeEvent()
SceneView::paintGL(): Rendering to: 1224 x 892
----

Ruft man stattdessen `renderLater()` auf, erhält man:

----
OpenGLWindow::resizeEvent()
OpenGLWindow::exposeEvent()
SceneView::paintGL(): Rendering to: 1283 x 910
SceneView::paintGL(): Rendering to: 1283 x 910
OpenGLWindow::resizeEvent()
OpenGLWindow::exposeEvent()
SceneView::paintGL(): Rendering to: 1288 x 912
SceneView::paintGL(): Rendering to: 1288 x 912
----

Wie man sieht, wird jedes Mal doppelt gezeichnet, was eine deutlich spürbare Verzögerung bedeutet. Grundsätzlich hilf es zu wissen, dass:

- beim ersten Anzeigen eines Fensters immer erst ein `ResizeEvent`, gefolgt von einem `ExposeEvent` geschickt wird
- beim Größenändern eines Fensters ebenfalls immer ein `ResizeEvent`, gefolgt von einem `ExposeEvent` geschickt wird 
- beim Minimieren und Maximieren eines Fensters nur je ein (oder auf dem Mac mehrere) `ExposeEvent` geschickt werden. Dies kann man nutzen, um eine Animation zu stoppen und beim erneuten Anzeigen (`isExposed() == true`) wieder zu starten. Dies ist aber nicht der Fokus in diesem Tutorial. Daher könnte man auch das `ExposeEvent` komplett ignorieren und `renderNow()` direkt am Ende von  `OpenGLWindow::resizeEvent()` aufrufen. So wie es aktuell implementiert ist, wird beim Minimieren und Maximieren mehrfach `ExposeEvent` mit `isExposed() == true` aufgerufen und damit wird mehrfach trotz unverändertem Viewport und unveränderte Szene gezeichnet. Das ist aber nicht weiter bemerkbar.

=== Verwendung der Klasse 'SceneView'

Die Klasse `SceneView` wird als QWindow-basierte Klasse selbst via Widget-Container in den Testdialog eingebettet (siehe __Tutorial 03__).

Bei der Analyse des Tutorialquelltextes kann man sich von außen nach innen "arbeiten":

- `main.cpp` - Instanziert `TestDialog`
- `TestDialog.cpp` - Instanziert `SceneView` und bettet das Objekt via Window-Container ein.

Es gibt im Quelltext von `TestDialog.cpp` nur ein neues Feature: Antialiasing (siehe Diskussion dazu im letzten Kapitel dieses Tutorials).

=== Implementierung der Klasse 'SceneView'

Und da wären wir auch schon bei der Implementierung des Klasse `SceneView`.

Im Konstruktor werden letztlich 3 Dinge gemacht:

- dem Tastatur/Maus-Eingabemanager werden die für uns interessanten Tasten mitgeteilt, siehe  Abschnitt "Tastatur- und Mauseingabe"
- die beiden ShaderProgramm-Container Objekte werden erstellt und konfiguriert, siehe Abschnitt "Shaderprogramme"
- die Kamera- und Welttransformationsmatrizen werden auf ein paar Standardwerte eingestellt, siehe Abschnitt "Transformationsmatrizen"

.SceneView.cpp, Konstruktor
[source,c++]
----
SceneView::SceneView() :
	m_inputEventReceived(false)
{
	// tell keyboard handler to monitor certain keys
	m_keyboardMouseHandler.addRecognizedKey(Qt::Key_W);
	m_keyboardMouseHandler.addRecognizedKey(Qt::Key_A);
	m_keyboardMouseHandler.addRecognizedKey(Qt::Key_S);
	m_keyboardMouseHandler.addRecognizedKey(Qt::Key_D);
	m_keyboardMouseHandler.addRecognizedKey(Qt::Key_Q);
	m_keyboardMouseHandler.addRecognizedKey(Qt::Key_E);
	m_keyboardMouseHandler.addRecognizedKey(Qt::Key_Shift);

	// *** create scene (no OpenGL calls are being issued below, just the data structures are created.

	// Shaderprogram #0 : regular geometry (painting triangles via element index)
	ShaderProgram blocks(":/shaders/withWorldAndCamera.vert",":/shaders/simple.frag");
	blocks.m_uniformNames.append("worldToView");
	m_shaderPrograms.append( blocks );

	// Shaderprogram #1 : grid (painting grid lines)
	ShaderProgram grid(":/shaders/grid.vert",":/shaders/simple.frag");
	grid.m_uniformNames.append("worldToView"); // mat4
	grid.m_uniformNames.append("gridColor"); // vec3
	grid.m_uniformNames.append("backColor"); // vec3
	m_shaderPrograms.append( grid );

	// *** initialize camera placement and model placement in the world

	// move objects a little bit to the back of the scene (negative z coordinates = further back)
	m_transform.translate(0.0f, 0.0f, -5.0f);
	m_camera.translate(0,5,0);
	m_camera.rotate(-30, m_camera.right());
}
----

[NOTE]
====
Im Konstruktor werden nur Eigenschaften für die Shaderprogramme festgelegt, die eigentliche Initialisierung (OpenGL-Aufrufe) findet in `initializeGL()` statt.
====

Im Destruktor der Klasse werden die OpenGL-Objekte wieder freigegeben:

.SceneView.cpp, Destruktor
[source,c++]
----
SceneView::~SceneView() {
	m_context->makeCurrent(this);

	for (ShaderProgram & p : m_shaderPrograms)
		p.destroy();

	m_boxObject.destroy();
	m_gridObject.destroy();
}
----

Wichtig ist hier, dass der OpenGL-Context für das aktuelle Fenster aktuell gesetzt wird (`m_context->makeCurrent(this)`). Damit können dann die OpenGL-Objekte freigegeben werden. Dies erfolgt in den `destroy()` Funktionen der Shaderprogramm-Wrapper-Klasse und DrawObjekt-Wrapper-Klassen.

=== OpenGL-Initialisierung

Die eigentlich Initialisierung der OpenGL-Objekte (Shaderprogramme und Pufferobjekte) erfolgt in `initializeGL()`:

.SceneView.cpp:initializeGL()
[source,c++]
----
#define SHADER(x) m_shaderPrograms[x].shaderProgram()

void SceneView::initializeGL() {
	// initialize shader programs
	for (ShaderProgram & p : m_shaderPrograms)
		p.create();

	// tell OpenGL to show only faces whose normal vector points towards us
	glEnable(GL_CULL_FACE);
	// enable depth testing, important for the grid and for the drawing order of several objects
	glEnable(GL_DEPTH_TEST);

	// initialize drawable objects
	m_boxObject.create(SHADER(0));
	m_gridObject.create(SHADER(1));
}
----

Dank der Kapselung der Shaderprogramm-Initialisierung in der Klasse `ShaderProgram`, und der Kapselung der Zeichenobjekt-spezifischen Initialisierung in den Objekten, ist diese Funktion sehr viel übersichtlicher als in den bisherigen Tutorials.

Das Makro `SHADER(x)` wird verwendet, um bequem auf das `QOpenGLShaderProgram` Objekt in der Wrapper-Klasse zuzugreifen.

Die beiden `glXXX` Befehle in der Mitte der Funktion schalten zwei für 3D Szenen wichtige Funktionen ein:

- `GL_CULL_FACE` - Zeichne Flächen nicht, welche mit dem "Rücken" zu uns stehen
- `GL_DEPTH_TEST` - Führe beim Zeichnen der Fragmente einen Tiefentest durch, und verwerfe weiter hintenliegende Fragmente. Das ist wichtig dafür, dass die gezeichneten Boxen das dahinterliegende Gitter überdecken. Der dafür benötigte Tiefenpuffer wird über `QSurfaceFormat` konfiguriert (https://doc.qt.io/qt-5/qsurfaceformat.html#setDepthBufferSize[QSurfaceFormat::setDepthBufferSize()]).

Die Funktion `glDepthFunc(GL_LESS)` muss nicht aufgerufen werden, da das bei OpenGL der Standard ist.

[TIP]
====
Man kann testweise mal das Flag `GL_DEPTH_TEST` nicht setzen - die etwas verwirrende Darstellung ist, nun ja, verwirrend.
====

== Tastatur- und Mauseingabe

Qt stellt in `QWindow` und `QWidget` Ereignisbehandlungsroutinen für Tastatur- und Mauseingaben zur Verfügung. Die Deklaration dieser Funktion sind oben in der `SceneView` Klassendeklaration zu sehen.

Wenn man eine Taste auf der Tastatur drückt, wird z.B. ein `QEvent::KeyPress` ausgelöst und die Memberfunktion `keyPressEvent(QKeyEvent *event)` aufgerufen. Das passiert auch, wenn man die Taste _gedrückt_ hält. Unterscheiden kann man dieses durch Prüfen der Eigenschaft `AutoRepeat` (`QKeyEvent::isAutoRepeat()`).

Für die Navigation in einer 3D Umgebung hält man die Tasten (z.B. WASD oder ähnliche) längere Zeit gedrückt (d.h. über mehrere Frames hinweg). Man benötigt also einen Zustandsmanager, der sich den aktuellen Zustand der Tasten merkt.

Ein solcher "Inputmanager" hält intern also für jede (berücksichtigte) Taste einen Zustand:

- Nicht gedrückt
- Gerade gedrückt
- Wurde gedrückt

Letzterer ist eigentlich nur dann wichtig, wenn auf einzelne Tastendrücke reagiert werden soll, während eventuell eine aufwändige Neuzeichenroutine läuft. 

Zunächst müssen wir uns den Programmauflauf der Ereignisschleife und Auswertung der Tasteneingabe genauer anschauen.


TODO


== Shaderprogramme

Die Verwaltung der Shaderprogramme macht Qt ja eigentlich schon durch die Klasse `QOpenGLShaderProgram`. Wenn man eine weitere Wrapper-Klasse außen herum packt, dann wird der Quelltext noch deutlich übersichtlicher. In der Deklaration der Wrapper-Klasse `ShaderProgram` findet man die gekapselte Qt Klasse wieder:

.ShaderProgram.h
[source,c++]
----
class ShaderProgram {
public:
	ShaderProgram();
	ShaderProgram(const QString & vertexShaderFilePath, const QString & fragmentShaderFilePath);

	void create();
	void destroy();

	QOpenGLShaderProgram * shaderProgram() { return m_program; }

    // paths to shader programs, used in create()
	QString		m_vertexShaderFilePath;
	QString		m_fragmentShaderFilePath;

	QStringList	m_uniformNames; // uniform (variable) names
	QList<int>	m_uniformIDs;   // uniform IDs (resolved in create())

private:
	QOpenGLShaderProgram	*m_program;
};
----

Zur Verwaltung von Shaderprogrammen gehören auch die Variablen, die man dem Vertex- und/oder Fragment-Shaderprogramm übergeben möchte (siehe Shaderprogramme in Abschnitt "Zeichenobjekte"). Die Verwendung der Klasse sieht vor, dass man erst alle Eigenschaften setzt (Resourcen-Pfade zu den Shaderprogrammen, und die uniform-Namen im Vektor `m_uniformNames`) und dann die Funktion `create()` aufruft. Die macht dann die eigentliche Initialisierung, die in den vorangegangenen Tutorials in der `initializeGL()` Funktion gemacht wurde:

.ShaderProgram.cpp:create()
[source,c++]
----
void ShaderProgram::create() {
	Q_ASSERT(m_program == nullptr);

	m_program = new QOpenGLShaderProgram();

	if (!m_program->addShaderFromSourceFile(QOpenGLShader::Vertex, m_vertexShaderFilePath))
		qDebug() << "Vertex shader errors:\n" << m_program->log();

	if (!m_program->addShaderFromSourceFile(QOpenGLShader::Fragment, m_fragmentShaderFilePath))
		qDebug() << "Fragment shader errors:\n" << m_program->log();

	if (!m_program->link())
		qDebug() << "Shader linker errors:\n" << m_program->log();

	m_uniformIDs.clear();
	for (const QString & uniformName : m_uniformNames)
		m_uniformIDs.append( m_program->uniformLocation(uniformName));
}
----
Dank der netten Hilfsfunktionen `QOpenGLShaderProgram::addShaderFromSourceFile()` und `QOpenGLShaderProgram::uniformLocation()` ist das auch recht übersichtlich. Die Fehlerbehandlung könnte noch besser sein, aber das kann man ja schnell nachrüsten.
[CAUTION]
====
Beim Aufruf von `QOpenGLShaderProgram::addShaderFromSourceFile()` das erste Argument beachten, welches den Typ des Shaderprogramms festlegt!
====

Die Funktion `uniformLocation()` sucht in beiden Shaderprogrammen nach `uniform` Deklarationen, also Variablen, die unabhängig von Vertex oder Fragment dem Shaderprogramm zur Verfügung stehen. Diese werden beim compilieren und linken durchnummeriert und den zu einem uniform-Variablennamen passenden Index kann man mit `uniformLocation()` ermitteln. 

Bei der Verwendung des Shaders kann man dann mit https://doc.qt.io/qt-5/qopenglshaderprogram.html#setUniformValue[setUniformValue()] den entsprechenden Wert setzen (siehe auch Shaderprogramm-Beispiele im Abschnitt "Zeichenobjekte"). 

Die Shaderprogramme wissen selbst nicht, für welche Objekte sie zum Zeichnen gebraucht werden. Auch werden die Variablen (uniforms), die sie zur Funktion benötigen, meist woanders gespeichert. Daher gibt es in der Klasse nicht mehr zu tun.

== Transformationsmatrizen und Kamera

=== Transformationen

Das Thema _Transformationsmatrizen_ ist in den in der Einleitung zitierten Webtutorials/Anleitungen ausreichend beschrieben. Die Format zur Transformation eines Punktes/Vektors `pModel` in den Modellkoordinaten zu den View-Koordinaten `pView` benötigt 3 Transformationsmatrizen:

    pView = M_projection * M_World2Camera * M_Model2World * pModel
    
Dies entspricht den Schritten:

1. Transformation des Punktes von Modellkoordinaten in das Weltenkoordinatensystem. Dies ist bei bewegten/animierten Objekten sinnvoll, d.h. eine Objekteigenschaft. Manchmal möchte man auch die gesamte Welt transformieren, auch dafür nimmt man die Model-zu-Welt-Transformationsmatrix.
2. Transformation von Welt- zu Beobachterkoordinatensystem (Kamera). Ist eigentlich das Gleiche, jedoch ist die Kamera, deren Ausrichtung und Position modellunabhängig.
3. Projektionstransformation (othogonal, perspektivisch, ...), kann z.B. durch near/far-plane und Angle-of-View definiert werden.

Da die Objekte in Modell bzw. Weltkoordinaten definiert und verwaltet werden, sollte besser OpenGL die Transformationen durchführen (dafür ist es ja gemacht). Je nach Anzahl der zu transformierenden Objekte kann nun den objektspezifischen ersten Transformationsschritt in das Weltenkoordinatensystem auf der CPU durchführen (idealerweise parallelisiert). Die Transformation von Weltkoordinaten in die projezierte Darstellung macht dann OpenGL. Da diese Matrix für _alle_ Objekte gleich ist, kann man diese auch bequem den Shaderprogrammen übergeben. D.h. die Matrix:

    M_World2View = M_Projection * M_World2Camera * M_Model2World
    
wird als uniform-Variable an die Shaderprogramme übergeben. Die Transformieren dann damit hocheffizient auf der Grafikkarte alle Vertex-Koordinaten.

=== Aktualisierung der World2View Matrix

Die Projektionsmatrix ändert sich bei jeder Viewport-Änderung, da sich damit zumeist das Breite/Höhe-Verhältnis ändert. Sonst ändert sich diese Matrix eigentlich nie, außer vielleicht in den Benutzereinstellungen (wenn z.B. Linseneigenschaften wie Öffnungswinkel oder Zoom verändert werden).

Die Model2World-Matrix bleibt wie oben geschrieben außen vor, da objektabhängig.

Die Kameramatrix (World2Camera) ändert sich jedoch ständig während der Navigation durch die Szene. Da die Navigation am Anfang der Neuzeichenroutine ausgewertet wird, erfolgt die Neuberechnung der Matrix (falls notwendig) auch direkt vorm Neuzeichnen.

[NOTE]
====
Es ist denkbar, dass ein MouseMove-Event mehrfach während eines Frames ausgelöst wird. Wenn man nun die Neuberechnung der Matrix daran koppelt, führt das mitunter zu unnützer Rechenarbeit. Daher ist es sinnvoller, die Berechnung erst zu Beginn des Zeichenzyklus durchzuführen.
====

Die eigentliche Berechnung erfolgt in der Funktion `updateWorld2ViewMatrix`. Dank der Funktionalität der Matrixklasse `QMatrix4x4` eine sehr kompakte Funktion.

[source,c++]
----
void SceneView::updateWorld2ViewMatrix() {
	// transformation steps:
	//   model space -> transform -> world space
	//   world space -> camera/eye -> camera view
	//   camera view -> projection -> normalized device coordinates (NDC)
	m_worldToView = m_projection * m_camera.toMatrix() * m_transform.toMatrix();
}
----

Die Multiplikation mit der Modell-Transformationsmatrix (`m_transform`) ist eigentlich nicht zwingend notwendig, dient aber der Demonstration der Animationsfähigkeit (konstantes Rotieren der Welt um die y-Achse). Dazu den `#if 0` Block in `paintGL()` nach `#if 1` ändern.



== Zeichenobjekte

In diesem Abschnitt geht es um die Verwaltung von Zeichenobjekten. Dies ist nicht wirklich ein Qt-Thema, da diese Art von Datenmanagement in der einen oder anderen Art in jeder OpenGL-Anwendung zu finden ist. Wen also nur die Qt-spezifischen Dinge interessieren, kann dieses Kapitel gerne überspringen.

=== Effizientes Zeichnen großer Geometrien

Es gibt eine wesentliche Grundregel in OpenGL:

[IMPORTANT]
====
Wenn man effizient große Geometrien zeichnen möchte, dann muss man die Anzahl der `glDrawXXX` Aufrufe so klein wie möglich halten.
====

Ein Beispiel: wenn man z.B. 2 Würfel zeichen möchte, hat man folgende Möglichkeiten:

- alle 12 Seiten einzeln Zeichen (12 `glDrawXXX` Aufrufe), z.B. als:
    * `GL_TRIANGLES` (6 Vertices)
    * `GL_TRIANGLE_STRIP` (4 Vertices) 
    * `GL_QUADS` (4 Vertices)
- jeden Würfel einzeln zeichnen (2 `glDrawXXX` Aufrufe), dabei alle Seiten des Würfels zusammen zeichnen via:
    * `GL_TRIANGLES` (8 Vertices, 6*6 Elementindices)
    * `GL_QUADS` (8 Vertices, 6*4 Elementindices)
- beide Würfel zusammen zeichnen (1 `glDrawXXX` Aufruf), dabei alle Seiten beider Würfels zusammen zeichnen via:
    * `GL_TRIANGLES` (2*8 Vertices, 2*6*6 Elementindices)
    * `GL_QUADS` (2*8 Vertices, 2*6*4 Elementindices)

Wenn man Objekte mit gemischten Flächenprimitiven hat (also z.B. Dreiecke und Rechtecke, oder Polygone), dann kann man entweder nach Flächentyp zusammenfassen und je Flächentyp ein `glDrawXXX` Aufruf ausführen, oder eben alles als Dreiecke behandeln und nur einen Zeichenaufruf verwenden. Kann man mal durch Profiling ausprobieren, was dann schneller ist. Der Speicherverbrauch spielt auch eine Rolle, da der Datentransfer zwischen CPU und GPU immer auch an der Geschwindigkeit der Speicheranbindung hängt.

=== Verwaltung von Zeichenobjekten

Eine Möglichkeit, die für das Zeichnen derart gruppierter Daten benötigten Objekte, d.h. VertexArrayObject (VAO), VertexBufferObject (VBO) und ElementBufferObject (EBO), zu verwalten, ist eigene Datenhalteklassen zu verwenden. Diese sehen allgemein so aus:

.Deklaration einer Zeichenobjektklasse
[source,c++]
----
class DrawObject {
public:
	DrawObject();

    // create native OpenGL objects
    void create(QOpenGLShaderProgram * shaderProgramm);
    // release native OpenGL objects
	void destroy();

    // actual render objects
	void render();

    // Data members to store state
    ....

    QOpenGLVertexArrayObject	m_vao;
	QOpenGLBuffer				m_vbo; // Vertex buffer
	QOpenGLBuffer				m_ebo; // Element/index buffer
	
	// other buffer objects
	
	....
};
----

Die drei wichtigen Lebenszyklusphasen der Objekte sind durch die Funktionen `create()`, `destroy()` und `render()` abgebildet.

[CAUTION]
====
Speichermanagement bei OpenGL Objekten sollte explizit erfolgen, und nicht im Destruktor von Klassen. Es ist beim Aufräumen im Destruktor durch die automatisiert generierte Aufrufreihenfolge der einzelnen Destruktoren schwierig sicherzustellen, dass der dazugehörige OpenGL-Kontext aktiv ist. Daher empfiehlt es sich, stets eine explizite `destroy()` Funktion zu verwenden.
====

Am Besten wird das Datenmanagement in einer Beispielimplementierung sichtbar.

=== Zeichenobjekt #1: Gitterraster in X-Z Ebene

Beginnen wir mit einem einfachen Beispiel: Ein Gitterraster soll auf dem Bildschirm gezeichnet werden, sozusagen als "Boden". Es werden also Linien in der X-Z-Ebene (y=0) gezeichnet, wofür der Elementtyp `GL_LINES` zum Zeichnen verwendet wird.

Für jede Linie sind Start- und Endkoordinaten anzugeben, wobei die y-Koordinate eingespart werden kann.

[TIP]
====
Man muss nicht immer alle Koordinaten (x,y,z) an den Vertexshader übergeben, wenn es nicht notwendig ist.
====

Wir stellen also den Vertexpuffer mit folgendem Schema zusammen:

`x1sz1sx1ez1ex2sz2sx2ez2e...` also jeweils x und z Koordinatentuple für je Start- (s) und Endpunkt (e) einer Linie nacheinander.

Diese Geometrieinformation wird in der Klasse `GridObject` zusammengestellt:

.GridObject.h, Klassendeklaration
[source,c++]
----
class GridObject {
public:
	void create(QOpenGLShaderProgram * shaderProgramm);
	void destroy();

	void render();

	unsigned int				m_bufferSize;
	QOpenGLVertexArrayObject	m_vao;
	QOpenGLBuffer				m_vbo;
};
----

Die Implementierung der `create()` Funktion ist das eigentlich Interessante:

.GridObject.cpp:create()
[source,c++]
----
void GridObject::create(QOpenGLShaderProgram * shaderProgramm) {
	const unsigned int N = 100; // number of lines to draw in x and z direction
	// width is in "space units", whatever that means for you (meters, km, nanometers...)
	float width = 500;
	// grid is centered around origin, and expands to width/2 in -x, +x, -z and +z direction

	// create a temporary buffer that will contain the x-z coordinates of all grid lines
	std::vector<float>			gridVertexBufferData;
	// we have 2*N lines, each line requires two vertexes, with two floats (x and z coordinates) each.
	m_bufferSize = 2*N*2;
	gridVertexBufferData.resize(m_bufferSize);
	float * gridVertexBufferPtr = gridVertexBufferData.data();
	// compute grid lines with z = const
	float x1 = -width*0.5;
	float x2 = width*0.5;
	for (unsigned int i=0; i<N; ++i, gridVertexBufferPtr += 4) {
		float z = width/(N-1)*i-width*0.5;
		gridVertexBufferPtr[0] = x1;
		gridVertexBufferPtr[1] = z;
		gridVertexBufferPtr[2] = x2;
		gridVertexBufferPtr[3] = z;
	}
	// compute grid lines with x = const
	float z1 = -width*0.5;
	float z2 = width*0.5;
	for (unsigned int i=0; i<N; ++i, gridVertexBufferPtr += 4) {
		float x = width/(N-1)*i-width*0.5;
		gridVertexBufferPtr[0] = x;
		gridVertexBufferPtr[1] = z1;
		gridVertexBufferPtr[2] = x;
		gridVertexBufferPtr[3] = z2;
	}
----

Im ersten Teil wird ein linearer Speicherbereich (bereitgestellt in einem `std::vector`) mit den Liniendaten gefüllt. Das Raster besteht aus Linien in X und Z Richtung (2), jeweils N Linien, und jede Linie hat einen Start- und einen Endpunkt (2) und jeder Punkt besteht aus 2 Koordinaten. Dies macht 2*N*2*2 floats (=NVertices). 

[NOTE]
====
Es ist ok an dieser Stelle den Speicherbereich in einem temporären Vektor anzulegen, da beim Erzeugen des OpenGL-Vertexpuffers die Daten kopiert werden und der Vektor danach nicht mehr benötigt wird. Dies ist im Falle von veränderlichen Daten (siehe BoxObjekte unten) anders.
====

Im zweiten Teil der Funktion werden dann wie gehabt die OpenGL-Pufferobjekte erstellt:


.GridObject.cpp:create(), fortgesetzt
[source,c++]
----
	// Create Vertex Array Object
	m_vao.create();		// create Vertex Array Object
	m_vao.bind();		// and bind it

	// Create Vertex Buffer Object
	m_vbo.create();
	m_vbo.bind();
	m_vbo.setUsagePattern(QOpenGLBuffer::StaticDraw);
	int vertexMemSize = m_bufferSize*sizeof(float);
	m_vbo.allocate(gridVertexBufferData.data(), vertexMemSize);

	// layout(location = 0) = vec2 position
	shaderProgramm->enableAttributeArray(0); // array with index/id 0
	shaderProgramm->setAttributeBuffer(0, GL_FLOAT,
								  0 /* position/vertex offset */,
								  2 /* two floats per position = vec2 */,
								  0 /* vertex after vertex, no interleaving */);

	m_vao.release();
	m_vbo.release();
}
----

Die Aufrufe von `shaderProgramm->enableAttributeArray` und `shaderProgramm->setAttributeBuffer` definieren, wie der Vertexshader auf diesen Speicherbereich zugreifen soll. Deshalb muss die Funktion `create()` auch das dazugehörige Shaderprogramm als Funktionsargument erhalten.

Nachdem nun die Puffer erstellt und konfiguriert wurden, ist der Rest der Klassenimplementierung recht übersichtlich:

.GridObject.cpp:destroy() und render()
[source,c++]
----
void GridObject::destroy() {
	m_vao.destroy();
	m_vbo.destroy();
}


void GridObject::render() {
	m_vao.bind();
	// draw the grid lines, m_bufferSize = number of floats in buffer
	glDrawArrays(GL_LINES, 0, m_bufferSize);
	m_vao.release();
}
----

Die Funktion `destroy()` ist sicher selbsterklärend. Und die Render-Funktion ebenso.

[CAUTION]
====
Beachte, dass die Funktion `glDrawArrays()` als drittes Argument die Länge des Puffers als Anzahl der Elemente vom Typ des Puffers (hier GL_FLOAT) erwartet, und _nicht_ die Länge in Bytes.
====

Das Ergebnis dieses Zeichnens (mit uniformer Gitterfarbe) ist zunächst ganz nett:

.Einfaches Gitterraster (einfarbig) mit sichtbarer endlicher Ausdehnung
image::Tutorial_05_gridplain.png[Raster,pdfwidth=8cm]

Aber schöne wäre es, wenn das Gitter mit zunehmender Tiefe verblasst.

=== Gitter mit Abblendung in der Tiefe

Das Gitter sollte sich nun in weiter Ferne der Hintergrundfarbe annähern. Man könnte das zum Beispiel erreichen, wenn man die Farbe des Gitters an weiter entfernten Punkte einfärbt.

Den Vertexshader könnte man wie folgt erweitern:

[source,c]
----
#version 330

// GLSL version 3.3
// vertex shader

layout(location = 0) in vec2 position; // input:  attribute with index '0' 
                                       //         with 2 floats (x, z coords) per vertex
out vec4 fragColor;                    // output: computed vertex color for shader

const float FARPLANE = 50;             // threshold
float fragDepth;                       // normalized depth value

uniform mat4 worldToView;              // parameter: the view transformation matrix
uniform vec3 gridColor;                // parameter: grid color as rgb triple
uniform vec3 backColor;                // parameter: background color as rgb triple

void main() {
  gl_Position = worldToView * vec4(position.x, 0.0, position.y, 1.0);
  fragDepth = max(0, min(1, gl_Position.z / FARPLANE));
  fragColor = vec4( mix(gridColor, backColor, fragDepth), 1.0);
}
----

Es gibt 3 Parameter, die dem Shaderprogramm gegeben werden müssen:

- `worldToView` - Transformationsmatrix (von Weltkoordinaten zur perspektivischen Ansicht)
- `gridColor` - Farbe des Gitters
- `backColor` - Hintergrundfarbe

Die Variable `gl_Position` enthält nach der Transformation die normalisierten Koordinaten. In der Berechnung wird die zweite Komponente des Vertex-Vektors (angesprochen über `.y`) als z-Koordinate verwendet.

Für die Abblendefunktionalität ist die Entfernung des Linienstart- bzw. -endpunktes  interessant. Nun sind die z-Koordinaten dieser normalisierten Position alle sehr dicht an 1 dran. Deshalb werden sie noch skaliert (entsprechend der perspektivischen Transformationsregeln etwas wie eine Farplane). Nun kann man diese Tiefe, gespeichert in der Variable `fragDepth` nutzen, um zwischen Gitterfarbe und Hintergrundfarbe linear mit der GLSL-Funktion `mix()` zu interpolieren.

.Gitterraster mit Vertex-basierter Abblendung
image::Tutorial_05_grid_vertexshaderfade.png[Gitter, Vertexshaderfade,pdfwidth=8cm]

Das Ergebnis geht schon in die richtige Richtung, aber es gibt einen unschönen Effekt, wenn man parallel zu den Linien schaut. Die Koordinaten der Endpunkte der seitlich laufenden Linien sind sehr weit weg (in der perspektivischen Projekten), sodass beide Linienenden nahezu Hintergrundfarbe bekommen. Und da die Fragmentfarbe eine lineare Interpolation zwischen den Vertexfarben ist, verschwindet die gesamte Linie.

Das Problem lässt sich nur beheben, wenn man die Ablendfunktionalität in den Fragment-Shader steckt.

Der Vertex-Shader wird dadurch total einfach:

.grid.vert (Vertexshader)
[source,c]
----
#version 330

// GLSL version 3.3
// vertex shader

layout(location = 0) in vec2 position; // input:  attribute with index '0'
                                       //         with 2 floats (x, z coords) per vertex

uniform mat4 worldToView;              // parameter: world to view transformation matrix

void main() {
  gl_Position = worldToView * vec4(position.x, 0.0, position.y, 1.0);
}
----

Letztlich werden nur noch die Vertex-Koordinaten transformiert und an den Shader weitergereicht. Der sieht dann so aus:

.grid.frag (Fragmentshader)
[source,c]
----
#version 330

out vec4 fColor;

uniform vec3 gridColor;                // parameter: grid color as rgb triple
uniform vec3 backColor;                // parameter: background color as rgb triple
const float FARPLANE = 150;            // threshold

void main() {
  float distanceFromCamera = (gl_FragCoord.z / gl_FragCoord.w) / FARPLANE;
  distanceFromCamera = max(0, min(1, distanceFromCamera)); // clip to valid value range
  fColor = vec4( mix(gridColor, backColor, distanceFromCamera), 1.0 );
}
----

Die Variable `gl_FragCoord` wird für jeden einzelnen Bildpunkt von OpenGL bereitgestellt und enthält die Normalized Device Coordinates (NDC). Wenn man beachtet, dass diese Koordinaten durch Division mit w berechnet werden, dann bekommt man die originale z-Koordinate durch Multiplikation mit w. Das ganze wird dann noch mit einem Begrenzungswert (`FARPLANE`) skaliert. Falls bei der Definition des View-Frustums andere Werte für Near/Farplane verwendet werden, muss man die Formel entsprechend anpassen.

Damit sieht das Ergebnis dann wie gewünscht aus:

.Gitterraster mit Fragment-basierter Abblendung
image::Tutorial_05_grid_fragshaderfade.png[Gitter, Fragmentshaderfade,pdfwidth=8cm]



== Antialiasing

Es gibt hier verschiedene Möglichkeiten, die wohl einfachste aus Sicht der Programmierung ist das Einschalten von Multisampling (MSAA) (siehe Erläuterung auf https://www.khronos.org/opengl/wiki/Multisampling).

Dazu muss man beim Konfigurieren des `QSurfaceFormat`-Objekts nur folgende Zeile hinzufügen:

[source,c++]
----
format.setSamples(4);	// enable multisampling (antialiasing)
----

Multisampling braucht mehr Grafikkartenspeicher und ist durch das mehrfache Samplen von Pixeln/Fragmenten natürlich langsamer. Daher gibt es auch die Möglichkeit, Antialiasing in das Shaderprogramm einzubauen.

TODO : Antialiased-Shader